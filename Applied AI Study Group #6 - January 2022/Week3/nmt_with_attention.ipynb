{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NMT: Neural Machine Translation With Attention\n",
    "\n",
    "In this notebook we will implement a RNN based sequence-to-sequence encoder-decoder architecture to translate one language to another using PyTorch. The model is from [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) by D Bahdanau, K Cho, Y Bengio.\n",
    ".\n",
    "\n",
    "**We will:**\n",
    "* Get the necessary data and try to represent a language\n",
    "* Preprocess the data to create pairs of utterences and create dataset splits with tokenization\n",
    "* Formulate the NMT task, and create, convert input-output pairs according to the task\n",
    "* Implement the Encoder, Attention, Decoder models in PyTorch\n",
    "* Combine these models to create Seq2Seq model its sequential forward pass.\n",
    "* Implement the training loop, train the model\n",
    "* Implement inference to translate at our will.\n",
    "* Check attention map to understand relation between input and output sentence.\n",
    "* Save and load the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Diagrams to understand NMT with Attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___________\n",
    "NMT task formulation\n",
    "\n",
    "![nmt_task_formulation.drawio.png](nmt_task_formulation.drawio.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_______\n",
    "\n",
    "General Encoder Decoder Model\n",
    "\n",
    "\n",
    "![](nmt_task_formulation-general_encoder_decoder_model.drawio.png)\n",
    "_____"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "sources:\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
    "- https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3\n",
    "- https://arxiv.org/pdf/1409.0473.pdf\n",
    "- https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\n",
    "- https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we import all the required modules."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from math import floor\n",
    "from typing import Tuple, List, Optional\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from datasets import tqdm\n",
    "import requests\n",
    "import zipfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the random seeds for reproducability."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Download Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def download_data(url, save_name=\"new_data.zip\"):\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    bar = tqdm(\n",
    "        total=int(r.headers[\"Content-Length\"]),\n",
    "        initial=0,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "    )\n",
    "\n",
    "    with open(save_name, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                bar.update(1024)\n",
    "    bar.close()\n",
    "\n",
    "# TODO: make this work actaully!\n",
    "def extract_data(saved_name=\"new_data.zip\"):\n",
    "    zipfile.ZipFile(saved_name).extractall()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0.00/2.88M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc4487de38c84bec84b0ea30f1b4886a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_url = \"https://download.pytorch.org/tutorial/data.zip\"\n",
    "download_data(data_url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/target'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_99696/1275108035.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mextract_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_99696/3113093530.py\u001B[0m in \u001B[0;36mextract_data\u001B[0;34m(saved_name)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mextract_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msaved_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"new_data.zip\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mzipfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msaved_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextractall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/target\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/anaconda3/envs/lit_template/lib/python3.8/zipfile.py\u001B[0m in \u001B[0;36mextractall\u001B[0;34m(self, path, members, pwd)\u001B[0m\n\u001B[1;32m   1645\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1646\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mzipinfo\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmembers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1647\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extract_member\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzipinfo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpwd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1648\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1649\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/lit_template/lib/python3.8/zipfile.py\u001B[0m in \u001B[0;36m_extract_member\u001B[0;34m(self, member, targetpath, pwd)\u001B[0m\n\u001B[1;32m   1691\u001B[0m         \u001B[0mupperdirs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtargetpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1692\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mupperdirs\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mupperdirs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1693\u001B[0;31m             \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mupperdirs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1694\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1695\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmember\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_dir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/lit_template/lib/python3.8/os.py\u001B[0m in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m         \u001B[0mmkdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    224\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mPermissionError\u001B[0m: [Errno 13] Permission denied: '/target'"
     ]
    }
   ],
   "source": [
    "extract_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Representing a language\n",
    " - Word level representation\n",
    " - Keeping Vocabulary\n",
    " - Easy conversion between word and its representation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sos_token_index = 1\n",
    "eos_token_index = 2\n",
    "pad_token_index = 0\n",
    "sos_token = '<start>'\n",
    "eos_token = '<end>'\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {sos_token:sos_token_index, eos_token: eos_token_index}\n",
    "        self.word2count = {sos_token:1, eos_token: 1}\n",
    "        self.index2word = {sos_token_index: sos_token, eos_token_index: eos_token}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "\n",
    "    def add_sentence(self, sentence: str):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word: str):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Before creating a language we need to preprocess the data!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def unicode_to_ascii(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "     NFD, 'Normal Form Decomposed' gives you decomposed, combined characters.\n",
    "    Mn, Nonspacing mark\n",
    "    :param sentence:\n",
    "    :return: ascii sentence\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', sentence)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SOURCE OF ALL EVIL!!! FIX THIS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def normalize_string(s: str) -> str:\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    # creating a space between a word and the punctuyouation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    s = re.sub(r\"([?.!,多])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"多\")\n",
    "    s = re.sub(r\"[^a-zA-Z?.!,多]+\", \" \", s)\n",
    "    return s.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'may i borrow this book ?'\n",
      "b'\\xc2\\xbf puedo tomar prestado este libro ?'\n",
      "b'puis je emprunter ce livre ?'\n"
     ]
    }
   ],
   "source": [
    "sentences = [u\"May I borrow this book?\",\n",
    "             u\"多Puedo tomar prestado este libro?\",\n",
    "             u\"Puis-je emprunter ce livre?\"]\n",
    "for sentence in sentences:\n",
    "    print(normalize_string(sentence).encode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset creation and tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def read_langs(lang1: str, lang2: str, num_examples: Optional[int] = None) -> (Lang, Lang, List[Tuple[str]]):\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8')\\\n",
    "        .read()\\\n",
    "        .strip()\\\n",
    "        .split('\\n')\n",
    "    if num_examples:\n",
    "        lines=lines[:num_examples]\n",
    "    print('Read %s lines' % len(lines))\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')[:2]] for l in lines]\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "MAX_LENGTH = 8\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def prepare_data(lang1: str, lang2: str, num_examples: Optional[int] = None):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2, num_examples)\n",
    "    print('Read %s sentence pairs' % len(pairs))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print('Counted words:')\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 lines\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 56621 sentence pairs\n",
      "Counted words:\n",
      "eng 7675\n",
      "fra 12835\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', None)\n",
    "num_examples=len(pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ll be at tom s .\n",
      "il n en est pas question !\n",
      "9 8\n"
     ]
    }
   ],
   "source": [
    "longest_input_sentence = sorted(map(lambda x: x[0], pairs), key=lambda x: len(x.split(' ')), reverse=True)[0]\n",
    "print(longest_input_sentence)\n",
    "# TODO: explain why we need those +2 and +1's\n",
    "longest_input_length = len(longest_input_sentence.split(' ')) + 2\n",
    "longest_output = sorted(map(lambda x: x[1], pairs), key=lambda x: len(x.split(' ')), reverse=True)[0]\n",
    "print(longest_output)\n",
    "longest_output_length = len(longest_output.split(' ')) + 1\n",
    "print(longest_input_length, longest_output_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['would you lend me your pen ?', 'me preterais tu ton stylo ?']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sentence - index - tensor conversions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang: Lang, sentence: str) -> List[int]:\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def sentence_from_indexes(lang: Lang, indexes):\n",
    "    return ' '.join([lang.index2word[index] for index in indexes])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes=indexes_from_sentence(lang, sentence)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def sentence_from_tensor(lang, tensor: torch.Tensor):\n",
    "    return sentence_from_indexes(lang, tensor.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def tensors_from_pair(input_lang, output_lang, pair):\n",
    "    input_tensor=tensor_from_sentence(input_lang,pair[0])\n",
    "    output_tensor=tensor_from_sentence(output_lang,pair[1])\n",
    "    return input_tensor, output_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def add_sos_eos_tokens_to_pair(pair):\n",
    "    source = ' '.join([sos_token, pair[0], eos_token])\n",
    "    target = ' '.join([pair[1], eos_token])\n",
    "    return source, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she explained her reasons to us .\n",
      "tensor([ 159, 4558,  369, 2452,  202,   52,    4], device='cuda:0')\n",
      "she explained her reasons to us .\n"
     ]
    }
   ],
   "source": [
    "sample_input = random.choice(pairs)[0]\n",
    "print(sample_input)\n",
    "sample_input_tensor = tensor_from_sentence(input_lang, sample_input)\n",
    "print(sample_input_tensor)\n",
    "print(sentence_from_tensor(input_lang, sample_input_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PyTorch Dataset and Dataloader creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 input_lang,\n",
    "                 output_lang,\n",
    "                 pairs,\n",
    "                 max_input_length: int,\n",
    "                 max_output_length: int):\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.pairs = pairs\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(pairs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            pair = pairs[item]\n",
    "            source, target = add_sos_eos_tokens_to_pair(pair)\n",
    "            input_tensor, output_tensor = tensors_from_pair(input_lang, output_lang, (source, target))\n",
    "            padded_input_tensor = torch.full([self.max_input_length], pad_token_index, dtype=torch.long, device=device)\n",
    "            padded_input_tensor[:len(input_tensor)] = input_tensor\n",
    "            padded_output_tensor = torch.full([self.max_output_length], pad_token_index, dtype=torch.long, device=device)\n",
    "            padded_output_tensor[:len(output_tensor)] = output_tensor\n",
    "        except Exception as e:\n",
    "            print('index', item)\n",
    "            print(pairs[item])\n",
    "            raise e\n",
    "        return {'source': padded_input_tensor, 'target': padded_output_tensor}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "dataset=NMTDataset(input_lang, output_lang, pairs, longest_input_length, longest_output_length)\n",
    "train_size=floor(num_examples*0.8)\n",
    "val_size= floor(num_examples*0.1)\n",
    "test_size=num_examples - train_size - val_size\n",
    "train_val_test_split = (train_size, val_size, test_size)\n",
    "\n",
    "data_train, data_val, data_test = random_split(\n",
    "                dataset, train_val_test_split, generator=torch.Generator().manual_seed(42)\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "batch_size=128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(\n",
    "            dataset=data_train,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,\n",
    "            pin_memory=False,\n",
    "            shuffle=True,\n",
    "        )\n",
    "val_dataloader=DataLoader(\n",
    "            dataset=data_val,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,\n",
    "            pin_memory=False,\n",
    "            shuffle=False,\n",
    "        )\n",
    "test_dataloader=DataLoader(\n",
    "            dataset=data_test,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,\n",
    "            pin_memory=False,\n",
    "            shuffle=False,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': tensor([   1,   61, 3262, 3263,    4,    2,    0,    0,    0], device='cuda:0'), 'target': tensor([  72, 2223, 5803, 1173, 5804,   15,    2,    0], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 9])\n",
      "torch.Size([128, 8])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "print(sample_batch['source'].shape)\n",
    "print(sample_batch['target'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Model and Attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        self.d = (1 if not self.rnn.bidirectional else 2) * self.rnn.num_layers\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor # B, L\n",
    "                ) -> Tuple[Tensor]:\n",
    "        embedded = self.dropout(self.embedding(src)) # B, L, E\n",
    "        outputs, hidden = self.rnn(embedded.permute(1, 0, 2)) # L, B, d*e_H - d, B, e_H\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))) # B, d_H\n",
    "        return outputs, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units)\n",
      " torch.Size([16, 32, 128])\n",
      "Encoder Hidden state shape: (batch size, decoder hidden size)\n",
      " torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randint(1, 100, (32, 16),  device=device)\n",
    "encoder = Encoder(input_lang.n_words, emb_dim=64, enc_hid_dim=64, dec_hid_dim=64).to(device=device)\n",
    "sample_encoder_output, sample_encoder_hidden = encoder(sample_input)\n",
    "print (f'Encoder output shape: (batch size, sequence length, units)\\n {sample_encoder_output.shape}')\n",
    "print (f'Encoder Hidden state shape: (batch size, decoder hidden size)\\n {sample_encoder_hidden.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoder with optional Global Attention Mechanism"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attn_dim: int):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "        self.v = nn.Parameter(torch.rand(attn_dim))\n",
    "\n",
    "    def forward(self,\n",
    "                decoder_hidden: torch.Tensor,  # [batch size, dec hid dim]\n",
    "                encoder_outputs: torch.Tensor  #  [src len, batch size, enc hid dim * 2]\n",
    "                ) -> torch.Tensor:\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        #repeat decoder hidden state src_len times\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        #decoder_hidden = [batch size, src sent len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "\n",
    "        # Step 1: to enable feeding through \"self.attn\" pink box above, concatenate\n",
    "        # `repeated_decoder_hidden` and `encoder_outputs`:\n",
    "        # torch.cat((hidden, encoder_outputs), dim = 2) has shape\n",
    "        # [batch_size, seq_len, enc_hid_dim * 2 + dec_hid_dim]\n",
    "\n",
    "        # Step 2: feed through self.attn to end up with:\n",
    "        # [batch_size, seq_len, attn_dim]\n",
    "\n",
    "        # Step 3: feed through tanh\n",
    "\n",
    "        energy = torch.tanh(self.attn(torch.cat((\n",
    "            repeated_decoder_hidden,\n",
    "            encoder_outputs),\n",
    "            dim = 2)))\n",
    "\n",
    "        #energy = [batch size, src sent len, attn_dim]\n",
    "\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "\n",
    "        #energy = [batch size, attn_dim, src sent len]\n",
    "\n",
    "        #v = [attn_dim]\n",
    "\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "\n",
    "        #v = [batch size, 1, attn_dim]\n",
    "\n",
    "        # High level: energy a function of both encoder element outputs and most recent decoder hidden state,\n",
    "        # of shape attn_dim x enc_seq_len for each observation\n",
    "        # v, being 1 x attn_dim, transforms this into a vector of shape 1 x enc_seq_len for each observation\n",
    "        # Then, we take the softmax over these to get the output of the attention function\n",
    "\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "\n",
    "        #attention= [batch size, src len]\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attention: nn.Module,\n",
    "                 dropout: float = 0.1, ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _weighted_encoder_rep(self,\n",
    "                              decoder_hidden: Tensor,\n",
    "                              encoder_outputs: Tensor) -> Tensor:\n",
    "        a = self.attention(decoder_hidden, encoder_outputs) # B, L\n",
    "        a = a.unsqueeze(1) # B, 1, L\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # B, L, d*e_H\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs) # B, 1, d*e_H\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2) # 1, B, d*e_H\n",
    "        return weighted_encoder_rep, a.squeeze(1)\n",
    "\n",
    "    def forward(self,\n",
    "                input: Tensor,\n",
    "                decoder_hidden: Tensor,\n",
    "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
    "        input = input.unsqueeze(0) # 1, B\n",
    "        embedded = self.dropout(self.embedding(input)) # 1, B, E\n",
    "        weighted_encoder_rep, attn_weights = self._weighted_encoder_rep(decoder_hidden,\n",
    "                                                          encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim=2)\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "        output = self.out(torch.cat((output,\n",
    "                                     weighted_encoder_rep,\n",
    "                                     embedded), dim=1))\n",
    "\n",
    "        return output, decoder_hidden.squeeze(0), attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch size, output_vocab_size)\n",
      " torch.Size([32, 12835])\n",
      "Decoder Hidden state shape: (batch size, decoder_hidden)\n",
      " torch.Size([32, 64])\n",
      "Decoder Attention Weights shape: (batch size, max_input_length)\n",
      " torch.Size([32, 16])\n"
     ]
    }
   ],
   "source": [
    "# Decoder with Attention Results\n",
    "sample_input = torch.randint(0, 1, (32, 1),  device=device)[:, 0]\n",
    "decoder = Decoder(output_dim= output_lang.n_words,\n",
    "                 emb_dim=64,\n",
    "                 enc_hid_dim=64,\n",
    "                 dec_hid_dim=64,\n",
    "                 attention=Attention(64, 64, 8)).to(device=device)\n",
    "sample_output, sample_hidden, attn_weights = decoder.forward(sample_input, sample_encoder_hidden, sample_encoder_output)\n",
    "print (f'Decoder output shape: (batch size, output_vocab_size)\\n {sample_output.shape}')\n",
    "print (f'Decoder Hidden state shape: (batch size, decoder_hidden)\\n {sample_hidden.shape}')\n",
    "print (f'Decoder Attention Weights shape: (batch size, max_input_length)\\n {attn_weights.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining Encoder + Decoder to create Seq2Seq model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    # TODO: implement inference mode\n",
    "    # TODO: show how important the teacher forcing ratio is\n",
    "    def forward(self,\n",
    "                source: torch.Tensor,\n",
    "                target: torch.Tensor,\n",
    "                teacher_forcing_ratio: float = 0.5) -> torch.Tensor:\n",
    "        batch_size = source.shape[0]\n",
    "        max_len = target.shape[1]\n",
    "        outputs = torch.zeros(batch_size, max_len, decoder.output_dim).to(device)\n",
    "        encoder_output, hidden = self.encoder(source)\n",
    "        # first input to the decoder is the <sos> token\n",
    "        output = Tensor([sos_token_index]).long().to(device=device).repeat(batch_size)\n",
    "        for t in range(max_len):\n",
    "            output, hidden, _ = self.decoder.forward(output, hidden, encoder_output)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top_v, top_i= output.topk(1)\n",
    "            if t + 1 is not max_len:\n",
    "                output = (target[:, t] if teacher_force else top_i.squeeze(1))\n",
    "\n",
    "        return outputs # B, L, V_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "ENC_EMB_DIM = 64\n",
    "DEC_EMB_DIM = 64\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256\n",
    "ATTN_DIM = 64\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "encoder = Encoder(input_dim=input_lang.n_words,\n",
    "                  enc_hid_dim=ENC_HID_DIM,\n",
    "                  emb_dim=ENC_EMB_DIM,\n",
    "                  dec_hid_dim=DEC_HID_DIM,\n",
    "                  dropout=ENC_DROPOUT\n",
    "                  ).to(device=device)\n",
    "decoder = Decoder(output_dim=output_lang.n_words,\n",
    "                  dec_hid_dim=DEC_HID_DIM,\n",
    "                  attention=Attention(enc_hid_dim=ENC_HID_DIM, dec_hid_dim=DEC_HID_DIM, attn_dim=ATTN_DIM),\n",
    "                  emb_dim=DEC_EMB_DIM,\n",
    "                  enc_hid_dim=ENC_HID_DIM,\n",
    "                  dropout=DEC_DROPOUT\n",
    "                  ).to(device=device)\n",
    "seq2seq = Seq2Seq(encoder, decoder).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 12835])\n"
     ]
    }
   ],
   "source": [
    "# Trying with sample batch\n",
    "outputs = seq2seq(source=sample_batch['source'], target=sample_batch['target'])\n",
    "print(outputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# add model visualization with parameter size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# tell them more about CrossEntropy loss why it is useful in this case\n",
    "def train_epoch(model: nn.Module,\n",
    "                iterator: DataLoader,\n",
    "                optimizer: optim.Optimizer,\n",
    "                criterion: nn.Module,\n",
    "                clip: float):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        src, trg = batch['source'].to(device=device), batch['target'].to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src, trg)\n",
    "        outputs = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss=criterion(outputs, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: DataLoader,\n",
    "              criterion: nn.Module):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        src, trg = batch['source'].to(device=device), batch['target'].to(device=device)\n",
    "        outputs = model(src, trg, teacher_forcing_ratio=0) #turn off teacher forcing\n",
    "        outputs = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss=criterion(outputs, trg)\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# Helper methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "model = seq2seq\n",
    "best_valid_loss = float('inf')\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_token_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 27s\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.692\n",
      "\t Val. Loss: 2.926 |  Val. PPL:  18.658\n",
      "Epoch: 02 | Time: 0m 26s\n",
      "\tTrain Loss: 2.241 | Train PPL:   9.401\n",
      "\t Val. Loss: 2.376 |  Val. PPL:  10.765\n",
      "Epoch: 03 | Time: 0m 27s\n",
      "\tTrain Loss: 1.631 | Train PPL:   5.109\n",
      "\t Val. Loss: 2.207 |  Val. PPL:   9.092\n",
      "Epoch: 04 | Time: 0m 26s\n",
      "\tTrain Loss: 1.326 | Train PPL:   3.766\n",
      "\t Val. Loss: 2.130 |  Val. PPL:   8.415\n",
      "Epoch: 05 | Time: 0m 26s\n",
      "\tTrain Loss: 1.124 | Train PPL:   3.078\n",
      "\t Val. Loss: 2.131 |  Val. PPL:   8.427\n",
      "Epoch: 06 | Time: 0m 27s\n",
      "\tTrain Loss: 0.999 | Train PPL:   2.716\n",
      "\t Val. Loss: 2.120 |  Val. PPL:   8.333\n",
      "Epoch: 07 | Time: 0m 26s\n",
      "\tTrain Loss: 0.890 | Train PPL:   2.435\n",
      "\t Val. Loss: 2.119 |  Val. PPL:   8.320\n",
      "Epoch: 08 | Time: 0m 27s\n",
      "\tTrain Loss: 0.808 | Train PPL:   2.244\n",
      "\t Val. Loss: 2.132 |  Val. PPL:   8.429\n",
      "Epoch: 09 | Time: 0m 26s\n",
      "\tTrain Loss: 0.744 | Train PPL:   2.105\n",
      "\t Val. Loss: 2.160 |  Val. PPL:   8.673\n",
      "Epoch: 10 | Time: 0m 25s\n",
      "\tTrain Loss: 0.685 | Train PPL:   1.983\n",
      "\t Val. Loss: 2.172 |  Val. PPL:   8.780\n",
      "| Test Loss: 2.192 | Test PPL:   8.954 |\n"
     ]
    }
   ],
   "source": [
    "# what is PPL: could it be perplexity\n",
    "epoch_losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    epoch_losses.append(train_loss)\n",
    "    valid_loss = evaluate(model, val_dataloader, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "test_loss = evaluate(model, test_dataloader, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot(epoch_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model: Seq2Seq, sentence: str, max_len: int):\n",
    "    sentence = ' '.join([sos_token, normalize_string(sentence), eos_token])\n",
    "    input_tensor = tensor_from_sentence(input_lang, sentence)\n",
    "    padded_input_tensor = torch.full([longest_input_length], pad_token_index, dtype=torch.long, device=device)\n",
    "    padded_input_tensor[:len(input_tensor)] = input_tensor\n",
    "    encoder_output, hidden = model.encoder(padded_input_tensor.view(1, -1))\n",
    "    decoder_attentions = torch.zeros(max_len, longest_input_length, device=device)\n",
    "    decoded_words = []\n",
    "    output = torch.tensor([sos_token_index], dtype=torch.long, device=device)\n",
    "    for t in range(max_len):\n",
    "        output, hidden, decoder_attention = model.decoder.forward(output, hidden, encoder_output)\n",
    "        decoder_attentions[t] = decoder_attention[0, :]\n",
    "        top_v, top_i= output.topk(1)\n",
    "        top_i = top_i.squeeze(1)\n",
    "        if top_i == eos_token_index:\n",
    "            decoded_words.append(eos_token)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[top_i.item()])\n",
    "        output = top_i.detach()\n",
    "\n",
    "    return decoded_words, decoder_attentions[:t]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def infer_randomly(model, n=5):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = infer(model, pair[0], longest_output_length)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you have such a beautiful name .\n",
      "= tu as un nom si beau .\n",
      "< tu as un si beau nom . <end>\n",
      "\n",
      "> they re looking for you .\n",
      "= ils te cherchent .\n",
      "< ils vous cherchent . <end>\n",
      "\n",
      "> are you in a hurry ?\n",
      "= tu es presse ?\n",
      "< etes vous presses ? <end>\n",
      "\n",
      "> let s take a rest here .\n",
      "= reposons nous ici .\n",
      "< reposons nous ici . <end>\n",
      "\n",
      "> i like to try new things .\n",
      "= j aime essayer de nouvelles choses .\n",
      "< j aime essayer de nouveau choses . <end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer_randomly(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i felt guilty .', 'je me suis sentie coupable .']\n"
     ]
    }
   ],
   "source": [
    "test_pair = random.choice(pairs)\n",
    "print(test_pair)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je', 'me', 'sentis', 'coupable', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "decoded_words, decoder_attentions = infer(model, test_pair[0], longest_output_length)\n",
    "print(decoded_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa3abbb0d60>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 518.4x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(decoder_attentions.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' '), rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def infer_and_show_attention(input_sentence):\n",
    "    output_words, attentions = infer(model, input_sentence, longest_output_length)\n",
    "    output = ' '.join(output_words)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', output)\n",
    "    attentions = attentions[:len(output.split(' ')), :len(input_sentence.split(' '))]\n",
    "    show_attention(input_sentence, output_words, attentions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i had some fun .\n",
      "output = je me suis marree . <end>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2097048/3749280879.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' '), rotation=90)\n",
      "/tmp/ipykernel_2097048/3749280879.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAItCAYAAAA32Q72AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe/UlEQVR4nO3df/Bld1kf8PfDJhCFQNQFlSSaqMFKgxWIYaz4o5bgIs5GG9Ek2jZgWaQNOkWcCRRjGxwdhGq1jTarYhhUUrQ/XMs6i/JjGAFlFxFigoE1INngrxWCChVY9ukf3xu9rLt7z7L7vfd+z3m9mDu559xzz31yMtk8vD+f8znV3QEAmLoHrLoAAIB1oCkCAIimCAAgiaYIACCJpggAIEly1qoLAADW344dO/rw4cNL+723ve1t+7p7x9J+MJoiAGCAw4cP58CBA0v7varavrQfm9EUAQCDjH1tQ3OKAAAiKQIABjoqKQIAGD9NEQBADJ8BAAN0TLQGAJgESREAMECnIykCABg9SREAsFgnR8cdFEmKAAASSREAMJC7zwAAJkBSBAAs1PGYDwCASZAUAQCDmFMEcBxV9cSqevrs/cOr6uJV1wRwOiRFwCmrqh9KclmSL03yC0nOTvKLSb56lXUBm0tSBPAPfWuSnUk+kiTd/YEk5660IoDTJCkCPh0f7+6uqk6SqnrwqgsCNld3u/sM4DheVVW3JDmvqp6Z5LeS/OyKawI4LZIi4JR190ur6ookf5WNeUU3dvdvrrgsgNOiKQI+Ld39m1X1u5n9OVJVn93dH1xxWcAmGvtEa00RcMqq6llJ/lOSv01yNEllY8HbL1plXQCnQ1MEfDqel+TS7j686kKA5elIimBLqKq/Tk78b2x3P3SJ5YzdHyX56KqLADiTNEWMRnefmyRV9aIkf5LkFdkY1vnOJJ+/wtLG6PlJ3jybU/Sx+3d29/euriRgM208EHbVVWwuTRFjtLO7/8nc9s9U1TuS3LiqgkboliSvS3J7NuYUcYZV1YOSXJXkosz9Wd3dN62qJhg7TRFj9JGq+s4kt2Xj/9xck9nKy5wxZ3f3c1ddxMj9WpIPJ3lb5tI4WCV3n8HWc22Sn5y9OsmbZvs4c36jqnYl+fV86vCZW/LPnAu6e8eqi4Ap0RQxOt39viRXrrqOkbtm9tfnz+1zS/6Z9eaqekx3377qQuB+Y3/Mh6aI0amqc5J8d5J/nOSc+/d39zNWVtTIdPfFq65hAp6Y5Lqqem820rhK0t395astC8ZLU8QYvSLJHyb5xiQ3ZePus3ettKKRqaqzkzw7ydfOdr0hyS3d/YmVFTU+T1l1AfApukc/p8gDYRmjL+nuH0zyke5+eZKnJnnCimsam59J8vgkPz17PX62jzOnT/ACNomkiDG6P624r6ouTfKnSR6xwnrG6CuPWfbgdbNlDzhzXp2NJqiyMQx8cZK7sjEsDEvXcfcZbEW7q+qzkrwwyZ4kD0nyg6staXQ+WVVf3N1/lCRV9UVJPrnimkalux8zv11Vj0vyb1dUDkyCpogxekX+ftG7l8/2fe7Kqhmn5yV5fVXdPdu+KMnTV1fO+HX371WVYWBWyt1nsPVY9G7zfU6SS7PRDH1Lkq/KxjXnDKmq+cUxH5CNeVsfWFE5MAmaIsbIoneb7we7+1eq6qFJ/lmSl2ZjorUk4zRV1Su6+19m47E0PzHbfSTJ/03yP1dWGEyApogxsujd5rt//tBTk/xsd7+6qn54lQWNyOOr6pFJ3p/kvx7z2Wcm+dvllwQbTLSGLaKqbs/GDRJnJXn6bL6LRe82x71VdUuSK5K8ePbwUkt8nBn/Pclrs3G32YG5/RWrhi9FVX1ed//pqutg+TRFS1JVv93dT6yqv86nrjVy/3+wH7qi0sbkm1ddwIR8e5IdSV7a3fdV1ecn+YEV1zQK3f1TSX6qqn6mu5+96nom6uezkYLyKTo98qWyNEVL0t1PnP313FXXMlbd/cerrmEquvujSf7X3PafJPmT1VU0Phqi1eluDdFEaYoAgIW6k6PjDorMAVilqtq16hrGzjXefK7xcrjOm881RlO0Wv4F3Hyu8eZzjZfDdd58rvECPXso7DJeq6ApAgDIiOYUVdWWHOncqnVvJVvtGm/bdvaqSzglD3jAtpx11gO31DX+7M/Zes8Hfsi55+URn3vBlrnOH77vg6su4ZRt23Z2HvSgz9wy1/jIkY/nk588Usv8TesUAUt13nkPX3UJo3fVtdevuoTR2/drr1x1CaN3773vWXUJo6MpAgAW6oz/gbDmFAEARFIEAAw09jlFkiIAgEiKAIAhus0pAgBYN1W1o6ruqqqDVXXDcT7/gqp6fVW9vareWVXftOicmiIAYEupqm1Jbk7ylCSPTnJNVT36mMNemORV3f3YJFcn+elF5zV8BgAMskYTrS9PcrC7706SqrotyZVJ7pw7ppM8dPb+YUk+sOikmiIAYB1tr6oDc9u7u3v37P35Se6Z++xQkicc8/3/mOQ1VfWcJA9O8qRFP6gpAgAW6iSdpSZFh7v7stP4/jVJbu3u/1xVX5XkFVV1aXcfPdEXzCkCALaae5NcOLd9wWzfvO9O8qok6e63JDknyfaTnVRTBAAMcrSX91pgf5JLquriqnpgNiZS7znmmPcn+edJUlVflo2m6C9OdlJNEQCwpXT3kSTXJ9mX5F3ZuMvsjqq6qap2zg77/iTPrKp3JHllkut6wUxxc4oAgEHW6O6zdPfeJHuP2Xfj3Ps7k3z1qZxTUgQAEEkRADDQOiVFm0FSBAAQSREAMEB7ICwAwDRIigCAQcwpAgCYAEkRADCIpAgAYAI0RQAAMXwGAAzQiVvyAQCmQFIEAAzSkRQBAIyepAgAGOTouIMiSREAQCIpAgCG6LZ4IwDAFEiKAICFOh7zAQAwCZIiAGAQK1oDAEyApAgAGMScIgCACZAUAQCDSIqWrKrevOoaAIDpWbumqLv/6aprAACmZ+2Gz6rqb7r7IVX1A0m+PcmDkvzv7v6hFZcGAJPV3W7JX4WqenKSS5JcnuQrkjy+qr72OMftqqoDVXVgySUCACOzdknRzJNnr7fPth+SjSbpjfMHdffuJLuTpKrG3b4CwIp1xv2f2nVtiirJj3b3LasuBACYhrUcPkuyL8kzquohSVJV51fVI1ZcEwBM2tFe3msV1jEp6u5+TVV9WZK3VFWS/E2S70ry5yutDAAYrbVqiqrqc5J8MEm6+yeT/ORqKwIAkqRj8calqapHJnlLkpeuuhYAYHrWJinq7g8kedSq6wAAjk9SBAAwAWuTFAEA682K1gAAEyApAgAW6zanCABgCiRFAMBC1ikCAJgISREAMIi7zwAAJkBTBAAQw2cAwEAdw2cAAKMnKQIABhn5PGtJEQBAIikCAAbouCUfAGASNEUAwGKzB8Iu67VIVe2oqruq6mBV3XCcz3+iqn5/9np3Vd236JyGzwCALaWqtiW5OckVSQ4l2V9Ve7r7zvuP6e5/P3f8c5I8dtF5NUUAwCBrNKfo8iQHu/vuJKmq25JcmeTOExx/TZIfWnRSw2cAwDraXlUH5l675j47P8k9c9uHZvv+gar6wiQXJ3ndoh+UFAEAC3UyaK7PGXS4uy87A+e5OsmvdvcnFx0oKQIAtpp7k1w4t33BbN/xXJ3klUNOKikCAAZZclJ0MvuTXFJVF2ejGbo6ybXHHlRV/yjJZyV5y5CTSooAgC2lu48kuT7JviTvSvKq7r6jqm6qqp1zh16d5LYe2M1JigCAQdbo7rN0994ke4/Zd+Mx2//xVM4pKQIAiKYIACCJ4TMAYJBOZ32GzzaDpAgAIJIiAGCA7o3XmEmKAAAiKQIABlqnW/I3g6QIACCSIgBgoDV6zMemkBQBAERSBAAM0Bn/nCJNEayZp3/vC1Zdwuh95rmfseoSRu/QobtWXcLoHTny8VWXMDqaIgBgEHOKAAAmQFIEACzWLSkCAJgCSREAMIykCABg/DRFAAAxfAYADNRHDZ8BAIyepAgAGGTk86wlRQAAiaQIABig22M+AAAmQVIEAAwiKQIAmABJEQAwgAfCAgBMgqQIABjEitYAABMgKQIAFrJOEQDAREiKAIBBJEUAABOgKQIAiOEzAGAow2cAAOMnKQIABhl5UCQpAgBIJEUAwBDdHvMBADAFkiIAYBCLNwIATICkCABYqCMpAgCYBEkRADCIpAgAYAIkRQDAIJIiAIAJkBQBAIt1J1a0BgBYL1W1o6ruqqqDVXXDCY759qq6s6ruqKpfXnROSREAsKVU1bYkNye5IsmhJPurak933zl3zCVJnp/kq7v7Q1X1iEXn1RQBAIOs0UTry5Mc7O67k6SqbktyZZI75455ZpKbu/tDSdLdf77opIbPAIB1tL2qDsy9ds19dn6Se+a2D832zXtUkkdV1Zuq6neqaseiH5QUAQCDLDkoOtzdl53G989KckmSr09yQZI3VtVjuvu+E31h6UlRVV1UVX9YVbdW1bur6peq6kmzTu49VXV5VT24ql5WVW+tqrdX1ZXLrhMAWFv3JrlwbvuC2b55h5Ls6e5PdPd7k7w7G03SCa0qKfqSJE9L8owk+5Ncm+SJSXYmeUE2xgRf193PqKrzkry1qn6ruz8yf5JZlDYfpwEAm2DNHgi7P8klVXVxNpqhq7PRS8z7P0muSfILVbU9G8Npd5/spKtqit7b3bcnSVXdkeS13d1VdXuSi7LR8e2squfNjj8nyRckedf8Sbp7d5Lds/OszT8pAGDzdPeRqro+yb4k25K8rLvvqKqbkhzo7j2zz55cVXcm+WSSH+juvzzZeVfVFH1s7v3Rue2j2ajpk0mu6u67ll0YAHAcvVZJUbp7b5K9x+y7ce59J3nu7DXIut59ti/Jc6qqkqSqHrviegCAkVvXu89elOS/JHlnVT0gyXuTfPNKKwKAieuRP+Zj6U1Rd78vyaVz29ed4LNnLbMuAGDa1jUpAgDWSq/VnKLNsK5zigAAlkpSBAAMIikCAJgASREAsFCv2TpFm0FSBAAQTREAQBLDZwDAUIbPAADGT1IEAAzSR1ddweaSFAEARFIEAAzklnwAgAmQFAEAi7UHwgIATIKkCAAYRFIEADABkiIAYKGOpAgAYBIkRQDAYp30UUkRAMDoSYoAgGHMKQIAGD9NEQBADJ8BAIN4zAcAwCRIigCAQUYeFEmKAAASSREAMJA5RQAAEyApAgAWao/5AACYBkkRADCIOUUAABMgKQIABpEUAQBMgKQIABjAs88AACZBUgRr5td+8dZVlzB6r9z3qlWXMHo//SMPX3UJo3fffX+23B9sc4oAACZBUwQAEMNnAMBQHvMBADB+kiIAYKHOxkNhx0xSBAAQSREAMJBb8gEAJkBSBAAs1h7zAQAwCZoiAGCQPtpLey1SVTuq6q6qOlhVNxzn8+uq6i+q6vdnr3+z6JyGzwCALaWqtiW5OckVSQ4l2V9Ve7r7zmMO/R/dff3Q82qKAIBB1mhO0eVJDnb33UlSVbcluTLJsU3RKTF8BgCso+1VdWDutWvus/OT3DO3fWi271hXVdU7q+pXq+rCRT8oKQIAFtpY0XqpSdHh7r7sNL7/60le2d0fq6pnJXl5km842RckRQDAVnNvkvnk54LZvr/T3X/Z3R+bbf5ckscvOqmmCABY7P6Hny3rdXL7k1xSVRdX1QOTXJ1kz/wBVfX5c5s7k7xr0UkNnwEAW0p3H6mq65PsS7Itycu6+46quinJge7ek+R7q2pnkiNJPpjkukXn1RQBAFtOd+9NsveYfTfOvX9+kuefyjk1RQDAAB7zAQAwCZIiAGCQPrrqCjaXpAgAIJIiAGAgc4oAACZAUgQALNaSIgCASZAUAQALreCBsEsnKQIAiKQIABhIUgQAMAGSIgBggE4flRQBAIyepAgAWMw6RQAA06ApAgCI4TMAYCjDZwAA4ycpAgAGGXlQJCkCAEgkRQDAAB4Iu2RVtbOqblh1HQDA9KxVUtTde5LsWXUdAMAxOh7zcbqq6sFV9eqqekdV/UFVfUdVva+qts8+v6yq3jB7f11V/bfZ+6fNjn9HVb1xs+sEAKZtGUnRjiQf6O6nJklVPSzJiwd878Yk39jd91bVecc7oKp2Jdl1pgoFAE6kzSk6A25PckVVvbiqvqa7Pzzwe29KcmtVPTPJtuMd0N27u/uy7r7sTBULAEzTpidF3f3uqnpckm9K8sNV9dokR/L3Ddk5J/je91TVE5I8Ncnbqurx3f2Xm10vAHB8kqLTVFWPTPLR7v7FJC9J8rgk70vy+NkhV53ge1/c3b/b3Tcm+YskF252rQDAdC1jTtFjkrykqo4m+USSZyf5jCQ/X1UvSvKGE3zvJVV1SZJK8tok71hCrQDACYw9KVrG8Nm+JPuO89GjjnPsrUlunb3/F5taGADAnLVapwgAWGMjT4rWakVrAIBVkRQBAAu1Fa0BAKZBUwQAEMNnAMBAI59nLSkCAEgkRQDAIB4ICwAwCZIiAGAQSREAwARIigCAxVpSBAAwCZIiAGChjsd8AABMgqQIABjEnCIAgAmQFAEAA/ToH34mKQIAiKQIABjCOkUAANOgKQIAtpyq2lFVd1XVwaq64STHXVVVXVWXLTqn4TMAYJB1GT2rqm1Jbk5yRZJDSfZX1Z7uvvOY485N8n1JfnfIeSVFAMBWc3mSg919d3d/PMltSa48znEvSvLiJH875KSaIgBgkD7aS3sl2V5VB+Zeu+ZKOT/JPXPbh2b7/k5VPS7Jhd396qF/f4bPAIB1dLi7F84DOp6qekCSH09y3al8T1MEACzUWatb8u9NcuHc9gWzffc7N8mlSd5QVUnyeUn2VNXO7j5wopMaPgMAtpr9SS6pqour6oFJrk6y5/4Pu/vD3b29uy/q7ouS/E6SkzZEiaQIABhijRZv7O4jVXV9kn1JtiV5WXffUVU3JTnQ3XtOfobj0xQBAFtOd+9NsveYfTee4NivH3JOTREAMECvTVK0WcwpAgCIpAgAGEhSBAAwAZIiAGCQ2UrToyUpAgCIpAgAGGJjSetVV7GpJEUAAJEUwdp5z3vetuoSRu/7n/6CVZcwer/6xtesuoTR2/W0p626hNHRFAEAC01g9MzwGQBAIikCAAayeCMAwARIigCAATwQFgBgEiRFAMBi7TEfAACTICkCAAYxpwgAYAIkRQDAQhsrWkuKAABGT1IEAAwiKQIAmABJEQAwQCeSIgCA8dMUAQDE8BkAMEQnfXTVRWwuSREAQCRFAMBAbskHAJgASREAMIikCABgAiRFAMBCHggLADARkiIAYLGWFAEATIKkCAAYoNNHJUUAAKMnKQIAhjGnCABg/CRFAMAgHUkRAMDoaYoAAGL4DAAYoC3eCAAwDZIiAGCATvfRVRexqSRFAACRFAEAA5lTBAAwAZIiAGAQSREAwAQsrSmqqrNOtg0ArLfuXtprkaraUVV3VdXBqrrhOJ9/T1XdXlW/X1W/XVWPXnTOhU1RVV1UVX9YVbdW1bur6peq6klV9aaqek9VXT57vaWq3l5Vb66qL51997qq2lNVr0vy2uNsP7iqXlZVb51998rZ97ZV1Uuqan9VvbOqnrXw6gAAk1BV25LcnOQpSR6d5JrjND2/3N2P6e6vSPJjSX580XmHpjVfkuRpSZ6RZH+Sa5M8McnOJC9I8q+SfE13H6mqJyX5kSRXzb77uCRf3t0frKrrjtn+kSSv6+5nVNV5Sd5aVb+V5DuTfLi7v7KqHpTkTVX1mu5+7zEXZVeSXQP/HgCAT9NGgrM26xRdnuRgd9+dJFV1W5Irk9x5/wHd/Vdzxz84Wfw026FN0Xu7+/bZD9+R5LXd3VV1e5KLkjwsycur6pLZj549993f7O4PnmD7yUl2VtXzZtvnJPmC2f4vr6pvm+1/WJJLknxKU9Tdu5PsntU17tlfADAt26vqwNz27tl/95Pk/CT3zH12KMkTjj1BVf27JM9N8sAk37DoB4c2RR+be390bvvo7BwvSvL67v7WqrooyRvmjv/IMeea364kV3X3XfMHVFUleU537xtYHwCw2ZZ799nh7r7sdE7Q3Tcnubmqrk3ywiT/+mTHn6mJ1g9Lcu/s/XWn8L19SZ4za4JSVY+d2//sqjp7tv9RVfXgM1QrALC13ZvkwrntC/L3fcjx3JbkWxad9Ew1RT+W5Eer6u05tbWPXpSNobZ3zoblXjTb/3PZGBf8var6gyS3nOJ5AYAzrJf4vwX2J7mkqi6uqgcmuTrJnvkDZlN67vfUJO9ZdNKFjUZ3vy/JpXPb153gs0fNfe2Fs89vTXLr3PHHbv+/JP/gzrLemMn1gtkLAODvzG7suj4bI0vbkrysu++oqpuSHOjuPUmun9389YkkH8qCobNE+gIAbEHdvTfJ3mP23Tj3/vtO9ZyaIgBgEI/5AACYAEkRADCIpAgAYAIkRQDAAGv1mI9NISkCAIikCAAYoNucIgCASZAUAQCDSIoAACZAUgQADCIpAgCYAEkRADBAb9yCNmKSIgCASIoAgIE6VrQGABg9TREAQAyfAQADuSUfAGACJEUAwEIeCAsAMBGSIgBggJYUAQBMgaQIABik2+KNAACjJykCAAYxpwgAYAIkRQDAIJIiAIAJkBQBAIttLGm96io2laQIACCSIgBggE7SkRQBAIyepggAIIbPAICBPOYDAGACJEUAwAA9+sUbNUWwdsb9h846eMc7Xr/qEkbv677slasuYfTOPeecVZcwOpoiAGCQsSdF5hQBAERSBAAMJCkCAJgASREAsNDG82CtUwQAMHqSIgBggPGvUyQpAgCIpAgAGEpSBAAwfpIiAGCQHvljiCRFAADRFAEAJDF8BgAM5JZ8AIA1U1U7ququqjpYVTcc5/PnVtWdVfXOqnptVX3honNKigCAAXptHvNRVduS3JzkiiSHkuyvqj3dfefcYW9Pcll3f7Sqnp3kx5J8x8nOKykCALaay5Mc7O67u/vjSW5LcuX8Ad39+u7+6Gzzd5JcsOikkiIAYKGNB8IudU7R9qo6MLe9u7t3z96fn+Seuc8OJXnCSc713Ul+Y9EPaooAgHV0uLsvO92TVNV3JbksydctOlZTBAAMskZ3n92b5MK57Qtm+z5FVT0pyX9I8nXd/bFFJzWnCADYavYnuaSqLq6qBya5Osme+QOq6rFJbkmys7v/fMhJJUUAwCDrkhR195Gquj7JviTbkrysu++oqpuSHOjuPUlekuQhSX6lqpLk/d2982Tn1RQBAFtOd+9NsveYfTfOvX/SqZ5TUwQADLIuSdFmMacIACCSIgBgkE7WZEXrzSIpAgCIpAgAGKhjThEAwOhpigAAYvgMABhgBQ+EXTpJEQBAJEUAwECSIgCACZAUAQADdNrijQAA4ycpAgAGMacIAGACJEUAwCCSIgCACZAUAQALWdEaAGAiJEUAwAC9EReNmKQIACCSIgBgoM64V7Te0k1RVe1KsmvVdQAAW9+Wboq6e3eS3UlSVeMe6ASAFXP3GQDABGiKAACyRZqiqtpbVY9cdR0AMGXdvbTXKmyJOUXd/U2rrgEAGLct0RQBAKu2ugRnWbbE8BkAwGaTFAEAC208EHbcizdKigAAIikCAAYypwgAYAIkRQDAIJIiAIAJkBQBAAP0xi1oIyYpAgCIpAgAGKgjKQIAGD1JEQAwiBWtAQAmQFMEABDDZwDAABsPhDXRGgBg9CRFAMAALSkCAJgCSREAMIikCABgAiRFAMAgkiIAgAnQFAEAg3QfXdprkaraUVV3VdXBqrrhOJ9/bVX9XlUdqapvG/L3pykCALaUqtqW5OYkT0ny6CTXVNWjjzns/UmuS/LLQ89rThEAsNjGktarruJ+lyc52N13J0lV3ZbkyiR33n9Ad79v9tngp9hKigCAdbS9qg7MvXbNfXZ+knvmtg/N9p0WSREAsFAn6Sw1KTrc3Zct8wclRQDAVnNvkgvnti+Y7TstkiIAYJA1Wqdof5JLquribDRDVye59nRPKikCALaU7j6S5Pok+5K8K8mruvuOqrqpqnYmSVV9ZVUdSvK0JLdU1R2LzispAgC2nO7em2TvMftunHu/PxvDaoNpigCAQYYsqriVGT4DAIikCAAYpNdpovWmkBQBAERSBAAMJCkCAJiAMSVFh5P88aqLOEXbs1E3m8c13nxb7hrfd9+frbqET8eWus5VteoSPh1b6hon+cJl/tjG82DHnRSNpinq7oevuoZTVVUHlv1cl6lxjTefa7wcrvPmc40ZTVMEAGyusSdF5hQBAERStGq7V13ABLjGm881Xg7XefO5xifVychXtK6xR2EAwOk766yz+2EP3b603/vgh/70bcue4yUpAgAG6Yw7SDGnCAAgkiIAYKCxT7mRFAEARFMEAJDE8BkAMJDhMwCACZAUAQALdXd65Is3SooAACIpAgAGMqcIAGACJEUAwCCSIgCACZAUAQCDSIoAACZAUgQADCMpAgAYP0kRADBAp2NFawCA0ZMUAQALdbv7DABgEjRFAAAxfAYADGT4DABgAiRFAMAgkiIAgAmQFAEAA7SkCABgCiRFAMAg3R7zAQAwepIiAGAhj/kAAJgISREAMIykCABg/CRFAMAAnY6kCABg9CRFAMAg1ikCAJgATREAQAyfAQADWbwRAGACJEUAwCCSIgCACZAUAQBD7EuyfYm/d3iJv5UkqbFHYQAAQxg+AwCIpggAIImmCAAgiaYIACCJpggAIEny/wEyWPCQy8xQKAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_and_show_attention('i had some fun .')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load models from checkpoint\n",
    "# TODO: add BLEU score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-lit-template",
   "language": "python",
   "display_name": "lit_template"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}