{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Batch no. 0 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   845.26904296875 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  849.69970703125 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    848.31201171875 MiB\n",
      "Cuda memory after updating test_preds: 848.31201171875 MiB\n",
      "Cuda memory after deleting X and y:    846.55419921875 MiB\n",
      "------------------\n",
      "Batch no. 1 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   846.55419921875 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  850.94873046875 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    1301.73681640625 MiB\n",
      "Cuda memory after updating test_preds: 1301.73681640625 MiB\n",
      "Cuda memory after deleting X and y:    1299.97900390625 MiB\n",
      "------------------\n",
      "Batch no. 2 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   1299.97900390625 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  1304.37353515625 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    1754.88818359375 MiB\n",
      "Cuda memory after updating test_preds: 1754.88818359375 MiB\n",
      "Cuda memory after deleting X and y:    1753.13037109375 MiB\n",
      "------------------\n",
      "Batch no. 3 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   1753.13037109375 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  1757.52490234375 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    2209.05126953125 MiB\n",
      "Cuda memory after updating test_preds: 2209.05126953125 MiB\n",
      "Cuda memory after deleting X and y:    2207.29345703125 MiB\n",
      "------------------\n",
      "Batch no. 4 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   2207.29345703125 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  2212.38330078125 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    2662.80419921875 MiB\n",
      "Cuda memory after updating test_preds: 2662.80419921875 MiB\n",
      "Cuda memory after deleting X and y:    2661.04638671875 MiB\n",
      "------------------\n",
      "Batch no. 5 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   2661.04638671875 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  2665.44091796875 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    3116.17724609375 MiB\n",
      "Cuda memory after updating test_preds: 3116.17724609375 MiB\n",
      "Cuda memory after deleting X and y:    3114.41943359375 MiB\n",
      "------------------\n",
      "Batch no. 6 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   3114.41943359375 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  3119.005859375 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    3568.7705078125 MiB\n",
      "Cuda memory after updating test_preds: 3568.7705078125 MiB\n",
      "Cuda memory after deleting X and y:    3567.0126953125 MiB\n",
      "------------------\n",
      "Batch no. 7 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   3567.0126953125 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  3571.59912109375 MiB\n",
      "Calling the model and calculating predictions...\n",
      "y_pred is in CPU\n",
      "Cuda memory after assigning y_pred:    4021.56591796875 MiB\n",
      "Cuda memory after updating test_preds: 4021.56591796875 MiB\n",
      "Cuda memory after deleting X and y:    4019.80810546875 MiB\n",
      "------------------\n",
      "Batch no. 8 out of 14\n",
      "At the beginning of the loop:\n",
      "X is in CPU\n",
      "y is in CPU\n",
      "Initial cuda memory:                   4019.80810546875 MiB\n",
      "Sending X and y to GPU...\n",
      "X is in GPU\n",
      "y is in GPU\n",
      "Cuda memory after sending X,y to GPU:  4024.39453125 MiB\n",
      "Calling the model and calculating predictions...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 6.00 GiB total capacity; 4.37 GiB already allocated; 0 bytes free; 4.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "\u001b[1;32m<ipython-input-10-a73e37f931ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cuda memory after sending X,y to GPU:  {} MiB'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calling the model and calculating predictions...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 20\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y_pred is in {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'CPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cuda memory after assigning y_pred:    {} MiB'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m<ipython-input-5-35bdd8e32cfc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    737\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 738\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    740\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myEnv001\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n",
      "\u001b[0;32m   1473\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1474\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1475\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1476\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 6.00 GiB total capacity; 4.37 GiB already allocated; 0 bytes free; 4.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Calculating predictions on the testset\n",
    "model.eval()\n",
    "test_preds = []\n",
    "torch.cuda.empty_cache()\n",
    "#model_ = model.cpu()\n",
    "for i, (X,y) in enumerate(test_loader):\n",
    "    # torch.cuda.empty_cache() # Doesn't make any difference. Doesn't delete anything.\n",
    "    print('------------------')\n",
    "    print('Batch no. %d out of %d'%(i,len(test_loader)))\n",
    "    print(\"At the beginning of the loop:\")\n",
    "    print('X is in {}'.format('GPU' if X.is_cuda else 'CPU'))\n",
    "    print('y is in {}'.format('GPU' if y.is_cuda else 'CPU'))\n",
    "    print('Initial cuda memory:                   {} MiB'.format(torch.cuda.memory_allocated() / 1024**2))\n",
    "    print(\"Sending X and y to GPU...\")\n",
    "    X,y = X.to(device), y.to(device)\n",
    "    print('X is in {}'.format('GPU' if X.is_cuda else 'CPU'))\n",
    "    print('y is in {}'.format('GPU' if y.is_cuda else 'CPU'))\n",
    "    print('Cuda memory after sending X,y to GPU:  {} MiB'.format(torch.cuda.memory_allocated() / 1024**2))\n",
    "    print(\"Calling the model and calculating predictions...\")\n",
    "    y_pred = model(X).float().cpu()\n",
    "    print('y_pred is in {}'.format('GPU' if y_pred.is_cuda else 'CPU'))\n",
    "    print('Cuda memory after assigning y_pred:    {} MiB'.format(torch.cuda.memory_allocated() / 1024**2))\n",
    "    test_preds.append(y_pred)\n",
    "    print('Cuda memory after updating test_preds: {} MiB'.format(torch.cuda.memory_allocated() / 1024**2))\n",
    "    del X\n",
    "    del y\n",
    "    print('Cuda memory after deleting X and y:    {} MiB'.format(torch.cuda.memory_allocated() / 1024**2))\n",
    "    # At this point X and y are totally deleted from workspace.\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
